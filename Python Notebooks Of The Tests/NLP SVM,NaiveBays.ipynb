{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>NLP with Support Vecter Machine And Naive Bays </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "twenty_train = fetch_20newsgroups(subset='train',shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alt.atheism',\n",
      " 'comp.graphics',\n",
      " 'comp.os.ms-windows.misc',\n",
      " 'comp.sys.ibm.pc.hardware',\n",
      " 'comp.sys.mac.hardware',\n",
      " 'comp.windows.x',\n",
      " 'misc.forsale',\n",
      " 'rec.autos',\n",
      " 'rec.motorcycles',\n",
      " 'rec.sport.baseball',\n",
      " 'rec.sport.hockey',\n",
      " 'sci.crypt',\n",
      " 'sci.electronics',\n",
      " 'sci.med',\n",
      " 'sci.space',\n",
      " 'soc.religion.christian',\n",
      " 'talk.politics.guns',\n",
      " 'talk.politics.mideast',\n",
      " 'talk.politics.misc',\n",
      " 'talk.religion.misc']\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "pprint(list(twenty_train.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_names = ['atheism','graphics','MS windows','pc hardware','mac hardware','windows','forsale','autos','motorcycles','baseball',\n",
    "              'hockey','cryptography','electronics','medical','space','christian','guns','mideast','politicsmisc','religen msc']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    "    p {\n",
    "        \n",
    "        color:'blue';\n",
    "            \n",
    "        \n",
    "    }\n",
    "\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: tg@cs.toronto.edu (Tom Glinos)\n",
      "Subject: 12V to 3V and 48V at 3A\n",
      "Organization: Department of Computer Science, University of Toronto\n",
      "Distribution: na\n",
      "Lines: 11\n",
      "\n",
      "The subject line says it all. I'm working on a project\n",
      "that will use a car battery. I need to pull off 3V and possibly\n",
      "48V at 3A.\n",
      "\n",
      "I have several ideas, but I'd prefer to benefit from all you\n",
      "brilliant people :-)\n",
      "-- \n",
      "=================\n",
      "\"Conquest is easy, control is not\"\t| Tom Glinos @ U of Toronto Statistics\n",
      "[Star Trek TOS]   \t\t\t| tg@utstat.toronto.edu\n",
      "USL forgot this simple history lesson\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Printing all the Catogaries\n",
    "twenty_train.target_names\n",
    "print((twenty_train.data[48][:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Extracting the Features From The Text</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Using Bag Of Words Model. Segment Each File to Words and Count number of times Each word Occors and Assign a id<p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11314, 130107)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(twenty_train.data)\n",
    "X_train_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11314, 130107)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfid_transformer = TfidfTransformer()\n",
    "X_train_tfid = tfid_transformer.fit_transform(X_train_counts)\n",
    "X_train_tfid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Running The Machine Learning ALgorithems </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Naive Bays</h3>\n",
    "\n",
    "<p>Using The Naive Bays Classifier in Sklearn and tranning it </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Accuracy of the Model With Stop Words</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                    ('tfidf', TfidfTransformer()),\n",
    "                    ('clf', MultinomialNB()) ])\n",
    "\n",
    "text_clf = text_clf.fit(twenty_train.data,twenty_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "twenty_test = fetch_20newsgroups(subset='test',shuffle=True)\n",
    "predicted = text_clf.predict(twenty_test.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7738980350504514"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(predicted == twenty_test.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     atheism       0.80      0.52      0.63       319\n",
      "    graphics       0.81      0.65      0.72       389\n",
      "  MS windows       0.82      0.65      0.73       394\n",
      " pc hardware       0.67      0.78      0.72       392\n",
      "mac hardware       0.86      0.77      0.81       385\n",
      "     windows       0.89      0.75      0.82       395\n",
      "     forsale       0.93      0.69      0.80       390\n",
      "       autos       0.85      0.92      0.88       396\n",
      " motorcycles       0.94      0.93      0.93       398\n",
      "    baseball       0.92      0.90      0.91       397\n",
      "      hockey       0.89      0.97      0.93       399\n",
      "cryptography       0.59      0.97      0.74       396\n",
      " electronics       0.84      0.60      0.70       393\n",
      "     medical       0.92      0.74      0.82       396\n",
      "       space       0.84      0.89      0.87       394\n",
      "   christian       0.44      0.98      0.61       398\n",
      "        guns       0.64      0.94      0.76       364\n",
      "     mideast       0.93      0.91      0.92       376\n",
      "politicsmisc       0.96      0.42      0.58       310\n",
      " religen msc       0.97      0.14      0.24       251\n",
      "\n",
      "   micro avg       0.77      0.77      0.77      7532\n",
      "   macro avg       0.83      0.76      0.76      7532\n",
      "weighted avg       0.82      0.77      0.77      7532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(twenty_test.target, predicted,target_names =group_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Accuracy of the Model With Out Stop Words</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "text_clf = Pipeline([('vect', CountVectorizer(stop_words='english')),\n",
    "                    ('tfidf', TfidfTransformer()),\n",
    "                    ('clf', MultinomialNB()) ])\n",
    "\n",
    "text_clf = text_clf.fit(twenty_train.data,twenty_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "twenty_test = fetch_20newsgroups(subset='test',shuffle=True)\n",
    "predicted = text_clf.predict(twenty_test.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8169144981412639"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(predicted == twenty_test.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     atheism       0.80      0.69      0.74       319\n",
      "    graphics       0.78      0.72      0.75       389\n",
      "  MS windows       0.79      0.72      0.75       394\n",
      " pc hardware       0.68      0.81      0.74       392\n",
      "mac hardware       0.86      0.81      0.84       385\n",
      "     windows       0.87      0.78      0.82       395\n",
      "     forsale       0.87      0.80      0.83       390\n",
      "       autos       0.88      0.91      0.90       396\n",
      " motorcycles       0.93      0.96      0.95       398\n",
      "    baseball       0.91      0.92      0.92       397\n",
      "      hockey       0.88      0.98      0.93       399\n",
      "cryptography       0.75      0.96      0.84       396\n",
      " electronics       0.84      0.65      0.74       393\n",
      "     medical       0.92      0.79      0.85       396\n",
      "       space       0.82      0.94      0.88       394\n",
      "   christian       0.62      0.96      0.76       398\n",
      "        guns       0.66      0.95      0.78       364\n",
      "     mideast       0.95      0.94      0.94       376\n",
      "politicsmisc       0.94      0.52      0.67       310\n",
      " religen msc       0.95      0.24      0.38       251\n",
      "\n",
      "   micro avg       0.82      0.82      0.82      7532\n",
      "   macro avg       0.84      0.80      0.80      7532\n",
      "weighted avg       0.83      0.82      0.81      7532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(twenty_test.target, predicted,target_names =group_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>In Naive Bays Removing Stop Words Incresed Accuracy from 77.38% to 81.69%</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Support Vecter Machine</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\smvdi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip...ndom_state=0, shuffle=True, tol=None,\n",
       "       validation_fraction=0.1, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# With Stop Words \n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "text_clf_svm = Pipeline([('vect', CountVectorizer()),\n",
    "                    ('tfidf', TfidfTransformer()),\n",
    "                    ('clf-svm', SGDClassifier(loss='hinge',penalty='l2',alpha=1e-3,n_iter=5,random_state=0)) ])\n",
    "text_clf_svm.fit(twenty_train.data,twenty_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "predicted_svm = text_clf_svm.predict(twenty_test.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8244822092405736"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(predicted_svm == twenty_test.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     atheism       0.73      0.71      0.72       319\n",
      "    graphics       0.80      0.70      0.75       389\n",
      "  MS windows       0.72      0.78      0.75       394\n",
      " pc hardware       0.73      0.68      0.71       392\n",
      "mac hardware       0.82      0.82      0.82       385\n",
      "     windows       0.84      0.76      0.80       395\n",
      "     forsale       0.84      0.90      0.87       390\n",
      "       autos       0.92      0.89      0.91       396\n",
      " motorcycles       0.94      0.96      0.95       398\n",
      "    baseball       0.90      0.90      0.90       397\n",
      "      hockey       0.88      0.99      0.93       399\n",
      "cryptography       0.83      0.96      0.89       396\n",
      " electronics       0.81      0.64      0.72       393\n",
      "     medical       0.88      0.85      0.86       396\n",
      "       space       0.85      0.96      0.90       394\n",
      "   christian       0.74      0.94      0.83       398\n",
      "        guns       0.70      0.92      0.80       364\n",
      "     mideast       0.90      0.93      0.92       376\n",
      "politicsmisc       0.87      0.56      0.68       310\n",
      " religen msc       0.83      0.39      0.53       251\n",
      "\n",
      "   micro avg       0.82      0.82      0.82      7532\n",
      "   macro avg       0.83      0.81      0.81      7532\n",
      "weighted avg       0.83      0.82      0.82      7532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(twenty_test.target, predicted_svm,target_names =group_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Removing Stop Words</h3>\n",
    "<p> removing words like the, then from the data becase these are not useful for the clsssification</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\smvdi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words='english',\n",
       "        ...ndom_state=0, shuffle=True, tol=None,\n",
       "       validation_fraction=0.1, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Without Stop Words\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "text_clf_svm = Pipeline([('vect', CountVectorizer(stop_words='english')),\n",
    "                    ('tfidf', TfidfTransformer()),\n",
    "                    ('clf-svm', SGDClassifier(loss='hinge',penalty='l2',alpha=1e-3,n_iter=5,random_state=0)) ])\n",
    "text_clf_svm.fit(twenty_train.data,twenty_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_svm = text_clf_svm.predict(twenty_test.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8228890069038768"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(predicted_svm == twenty_test.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     atheism       0.72      0.71      0.71       319\n",
      "    graphics       0.78      0.70      0.74       389\n",
      "  MS windows       0.73      0.79      0.76       394\n",
      " pc hardware       0.72      0.68      0.70       392\n",
      "mac hardware       0.82      0.82      0.82       385\n",
      "     windows       0.86      0.76      0.80       395\n",
      "     forsale       0.82      0.87      0.84       390\n",
      "       autos       0.91      0.89      0.90       396\n",
      " motorcycles       0.94      0.97      0.95       398\n",
      "    baseball       0.89      0.92      0.90       397\n",
      "      hockey       0.87      0.98      0.93       399\n",
      "cryptography       0.85      0.96      0.90       396\n",
      " electronics       0.81      0.62      0.70       393\n",
      "     medical       0.90      0.87      0.88       396\n",
      "       space       0.84      0.96      0.90       394\n",
      "   christian       0.74      0.93      0.82       398\n",
      "        guns       0.70      0.93      0.80       364\n",
      "     mideast       0.92      0.92      0.92       376\n",
      "politicsmisc       0.89      0.56      0.69       310\n",
      " religen msc       0.80      0.39      0.52       251\n",
      "\n",
      "   micro avg       0.82      0.82      0.82      7532\n",
      "   macro avg       0.82      0.81      0.81      7532\n",
      "weighted avg       0.83      0.82      0.82      7532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(twenty_test.target, predicted_svm,target_names =group_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Optimizing the Performance Of the Model</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Grid Search For Naive Bays</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "parameters = {'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "              'tfidf__use_idf': (True, False),\n",
    "              'clf__alpha': [0.009,0.008,0.01,0.02]}\n",
    "\n",
    "text_clf = Pipeline([('vect', CountVectorizer(stop_words='english')),\n",
    "                    ('tfidf', TfidfTransformer()),\n",
    "                    ('clf', MultinomialNB()) ])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\smvdi\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "gs_clf = GridSearchCV(text_clf, parameters, n_jobs=-1)\n",
    "gs_clf = gs_clf.fit(twenty_train.data, twenty_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__alpha': 0.02, 'tfidf__use_idf': True, 'vect__ngram_range': (1, 1)}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.905957221141948"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_clf.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>IN Naive Bays The Accuracy Of the Model Increased <br> It Was Computationlally intensive Rather than Just Using the Model <br>\n",
    "    <ul>\n",
    "        <li>Accuracy Normal : 77.3898 %</li>\n",
    "        <li>Accuracy (After Removing Stop Words): 81.6914 % </li>\n",
    "        <li>Accuracy After Applying Grid Serch: 90.5957 % </li>\n",
    "        \n",
    "   </ul>\n",
    "\n",
    "\n",
    "\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Grid Search For SVM</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "parameters_svm = {'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "                   'tfidf__use_idf': (True, False),\n",
    "                   'clf-svm__alpha': [0.0008,0.0009,0.001,0.002]}\n",
    "\n",
    "\n",
    "text_clf_svm = Pipeline([('vect', CountVectorizer(stop_words='english')),\n",
    "                    ('tfidf', TfidfTransformer()),\n",
    "                    ('clf-svm', SGDClassifier(loss='hinge',penalty='l2',alpha=1e-3,n_iter=5,random_state=0)) ])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\smvdi\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Users\\smvdi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "gs_clf_svm = GridSearchCV(text_clf_svm, parameters_svm, n_jobs=-1)\n",
    "gs_clf_svm = gs_clf_svm.fit(twenty_train.data, twenty_train.target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf-svm__alpha': 0.0009, 'tfidf__use_idf': True, 'vect__ngram_range': (1, 2)}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_clf_svm.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8962347534028637"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_clf_svm.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>In SVM The Accuracy Of the Model Increased only sightly compaied to Naive Bays<br> \n",
    "Training the Model with Grid Search Was Computationlally intensive Rather than Just Using the Model just <br>\n",
    "    <ul>\n",
    "        <li>Accuracy Normal : 82.4482 %</li>\n",
    "        <li>Accuracy (After Removing Stop Words): 82.288 % </li>\n",
    "        <li>Accuracy After Applying Grid Serch: 89.5881 % </li>\n",
    "        \n",
    "   </ul>\n",
    "\n",
    "\n",
    "\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Logistic Regression</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\smvdi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\smvdi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip...penalty='l2', random_state=None,\n",
       "          solver='warn', tol=0.0001, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = Pipeline([('vect', CountVectorizer()),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', LogisticRegression(n_jobs=1, C=1e5)),\n",
    "               ])\n",
    "logreg.fit(twenty_train.data, twenty_train.target)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "predicted_lg = logreg.predict(twenty_test.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8481147105682422"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(predicted_lg == twenty_test.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     atheism       0.81      0.80      0.81       319\n",
      "    graphics       0.75      0.80      0.78       389\n",
      "  MS windows       0.77      0.72      0.74       394\n",
      " pc hardware       0.70      0.73      0.72       392\n",
      "mac hardware       0.83      0.85      0.84       385\n",
      "     windows       0.85      0.76      0.80       395\n",
      "     forsale       0.82      0.89      0.85       390\n",
      "       autos       0.92      0.91      0.91       396\n",
      " motorcycles       0.96      0.96      0.96       398\n",
      "    baseball       0.93      0.94      0.93       397\n",
      "      hockey       0.95      0.98      0.97       399\n",
      "cryptography       0.94      0.93      0.94       396\n",
      " electronics       0.78      0.79      0.79       393\n",
      "     medical       0.90      0.86      0.88       396\n",
      "       space       0.90      0.93      0.91       394\n",
      "   christian       0.85      0.93      0.89       398\n",
      "        guns       0.74      0.91      0.82       364\n",
      "     mideast       0.97      0.88      0.92       376\n",
      "politicsmisc       0.82      0.61      0.70       310\n",
      " religen msc       0.75      0.64      0.69       251\n",
      "\n",
      "   micro avg       0.85      0.85      0.85      7532\n",
      "   macro avg       0.85      0.84      0.84      7532\n",
      "weighted avg       0.85      0.85      0.85      7532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(twenty_test.target, predicted_lg,target_names =group_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Without Stop Words</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8479819437068508"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf_lg = Pipeline([('vect', CountVectorizer(stop_words='english')),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', LogisticRegression(n_jobs=1, C=1e5)),\n",
    "               ])\n",
    "text_clf_lg.fit(twenty_train.data, twenty_train.target)\n",
    "\n",
    "predicted_lg = text_clf_lg.predict(twenty_test.data)\n",
    "np.mean(predicted_lg == twenty_test.target)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Using Grid Search</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "              'tfidf__use_idf': (True, False),\n",
    "             'clf__C':[0.8,0.9,1,2,10],\n",
    "             'clf__penalty': [\"l1\",\"l2\"]}\n",
    "              \n",
    "\n",
    "text_clf_lg = Pipeline([('vect', CountVectorizer(stop_words='english')),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', LogisticRegression(n_jobs=1)),\n",
    "                   ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\smvdi\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Users\\smvdi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\smvdi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "gs_clf_log = GridSearchCV(text_clf_lg, parameters, n_jobs=-1)\n",
    "gs_clf_log = gs_clf_log.fit(twenty_train.data, twenty_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__C': 10,\n",
       " 'clf__penalty': 'l2',\n",
       " 'tfidf__use_idf': True,\n",
       " 'vect__ngram_range': (1, 2)}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_clf_log.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9112603853632667"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_clf_log.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<P> In Logistic Regression again we have no notable difference while removing the Stop Words <br>\n",
    "but just training the model gives us < 80% accuracy \n",
    "<ul>\n",
    "        <li>Accuracy Normal : 84.8114 %</li>\n",
    "        <li>Accuracy (After Removing Stop Words): 84.7981 % </li>\n",
    "        <li>Accuracy After Applying Grid Serch: 91.7977 % </li>\n",
    "        \n",
    "</ul>\n",
    "\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Logistic_grid.sav']"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "joblib.dump(gs_clf_log,\"Logistic_grid.sav\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_clf_logistic = Pipeline([('vect', CountVectorizer(stop_words='english',ngram_range=(1, 2))),\n",
    "                ('tfidf', TfidfTransformer(use_idf= True)),\n",
    "                ('clf', LogisticRegression(n_jobs=1,C=10),penalty=l2'),\n",
    "                   ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\smvdi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\smvdi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "text_clf_logistic = text_clf_logistic.fit(twenty_train.data, twenty_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_opt = text_clf_logistic.predict(twenty_test.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8462559745087627"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(log_opt == twenty_test.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Logistic_20News.sav']"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "joblib.dump(text_clf_logistic,\"Logistic_20News.sav\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
